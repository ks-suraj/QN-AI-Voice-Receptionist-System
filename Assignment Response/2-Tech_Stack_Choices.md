| Component Category             | **My Choice Choice**                                       | **Why This?**                                                                                                                                               | **Trade-offs**                                                                         |
| ------------------------------ | ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| **Backend Runtime**            | **Python (FastAPI microservices)**                    | AI ecosystem, multiple ML,AI,Automation libraries, supports async programming, easy and faster development, personal experience  | lower throughput compared to Go/Rust, yet acceptable as AI ecosystem would dominate |
| **Web Framework**              | **FastAPI**                                           | Aync I/O availability, supports pydantic, developer friendly and faster, easier and adaptable                 | a sacrifice on latency w.r.t Go servers yet faster developer ecosystem                            |
| **Primary Database**           | **PostgreSQL**                                        | Strong relational model for call logs, users, routing rules, dispositions. Mature, reliable, ACID compliant.                                                | Not ideal for massive unstructured data (handled by S3 instead).                       |
| **Cache Layer**                | **Redis**                                             | Ultra-low latency for session state, ephemeral call context, and throttling. Works perfectly with streaming workloads.                                      | Requires careful eviction strategy; Redis loss = loss of volatile state.               |
| **Message Queue**              | **Kafka**                                             | High throughput, durable, excellent for event-driven pipelines (transcripts, intents, dispositions). Allows async decoupling of ASR → NLU → LLM.            | Operationally heavy; more complex cluster management vs. RabbitMQ.                     |
| **Vector / Search DB**         | **Pinecone or Weaviate**                              | Optimized for semantic retrieval and RAG. High-speed ANN search ensures minimal LLM latency.                                                                | SaaS pricing can be expensive at very large scale; lock-in risk.                       |
| **Job Scheduler**              | **Celery + Redis / Kubernetes CronJobs**              | Reliable asynchronous task execution for batch transcription, archiving, analytics ETL.                                                                     | Less suitable for extremely high throughput; needs monitoring.                         |
| **Monitoring & Logging**       | **Prometheus + Grafana + ELK (ElasticSearch / Loki)** | Complete observability: SIP metrics, ASR latency, LLM latency, queue lag, TTS errors.                                                                       | Operational overhead of running ELK stack; storage-heavy.                              |
| **Deployment & Orchestration** | **Kubernetes (EKS/GKE)**                              | Best fit for auto-scaling media servers, ASR workers, LLM inference microservices, and stateless APIs. Enables horizontal scaling for 10× traffic.          | Requires DevOps maturity; costly at early stage.                                       |
