| Component Category             | **Your Choice**                                       | **Why This?**                                                                                                                                               | **Trade-offs**                                                                         |
| ------------------------------ | ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| **Backend Runtime**            | **Python (FastAPI microservices)**                    | Python has the richest ecosystem for AI, NLU, and audio processing. FastAPI supports async I/O for streaming ASR/TTS and scales well with Uvicorn/Gunicorn. | Slightly slower raw performance than Go or Rust. Needs tuning for extreme concurrency. |
| **Web Framework**              | **FastAPI**                                           | Native async support, excellent for low-latency real-time endpoints, clean schema with Pydantic, easy integration with ASR/LLM pipelines.                   | Not as fast as Go Fiber or Node.js for raw TCP-heavy tasks.                            |
| **Primary Database**           | **PostgreSQL**                                        | Strong relational model for call logs, users, routing rules, dispositions. Mature, reliable, ACID compliant.                                                | Not ideal for massive unstructured data (handled by S3 instead).                       |
| **Cache Layer**                | **Redis**                                             | Ultra-low latency for session state, ephemeral call context, and throttling. Works perfectly with streaming workloads.                                      | Requires careful eviction strategy; Redis loss = loss of volatile state.               |
| **Message Queue**              | **Kafka**                                             | High throughput, durable, excellent for event-driven pipelines (transcripts, intents, dispositions). Allows async decoupling of ASR → NLU → LLM.            | Operationally heavy; more complex cluster management vs. RabbitMQ.                     |
| **Vector / Search DB**         | **Pinecone or Weaviate**                              | Optimized for semantic retrieval and RAG. High-speed ANN search ensures minimal LLM latency.                                                                | SaaS pricing can be expensive at very large scale; lock-in risk.                       |
| **Job Scheduler**              | **Celery + Redis / Kubernetes CronJobs**              | Reliable asynchronous task execution for batch transcription, archiving, analytics ETL.                                                                     | Less suitable for extremely high throughput; needs monitoring.                         |
| **Monitoring & Logging**       | **Prometheus + Grafana + ELK (ElasticSearch / Loki)** | Complete observability: SIP metrics, ASR latency, LLM latency, queue lag, TTS errors.                                                                       | Operational overhead of running ELK stack; storage-heavy.                              |
| **Deployment & Orchestration** | **Kubernetes (EKS/GKE)**                              | Best fit for auto-scaling media servers, ASR workers, LLM inference microservices, and stateless APIs. Enables horizontal scaling for 10× traffic.          | Requires DevOps maturity; costly at early stage.                                       |
